---
title: "Pipeline for Simulating and Analyzing Forest Data"
author: "Adam J. Eichenwald"
date: "`r Sys.Date()`"
output: html_document
---

# Introduction

In this document, we outline a pipeline to simulate forest data, assess tree visibility for remote sensing, and estimate the alpha parameter of a truncated Pareto distribution using a sliding truncation point. This approach allows us to understand how canopy structure and tree abundance distribution may influence remote sensing measurements and validate whether our model can recover the true alpha values under varying levels of truncation.

## Pipeline Overview

This pipeline involves the following key steps:

1. **Forest Simulation**: We generate a synthetic forest scene based on a specified alpha parameter of the Pareto distribution. Tree attributes, such as diameter at breast height (DBH), height, and crown diameter, are calculated based on biome and tree classification (angiosperm or gymnosperm), giving us realistic forest structure.

2. **Visibility Analysis**: We determine which trees in the simulated forest would be visible from remote sensing. Trees' visibility is influenced by their height, crown diameter, and positioning relative to other trees, allowing us to approximate remote sensing's line of sight within the canopy.

3. **Sliding Truncation Point Model Fitting**: We fit a model to the truncated data, varying the truncation point systematically. This approach aims to determine if the alpha parameter can be accurately recovered from a limited dataset, exploring how truncation affects the estimation process.

Through this document, we will analyze the results to assess the model’s performance in estimating alpha values across different truncation points and tree visibility scenarios.

## Objectives

- Simulate a realistic forest structure with diverse tree attributes.
- Determine tree visibility for remote sensing applications.
- Evaluate a sliding truncation point model for estimating alpha from truncated data.

```{r, warning=FALSE,message=FALSE, echo= FALSE}
library(rstan)
library(rstantools)
library(dplyr)
library(VGAM)
library(ggplot2)
library(data.table)
library(itcSegment)
```
### Forest Simulation and Data Export

This section of code automates the simulation and storage of forest data files with varying alpha values (shape parameters for DBH distributions). The goal is to generate a specified number of forest datasets (`n_forests`) across a given alpha range, representing different distributions of tree sizes. Each simulated forest reflects a specific tree species composition and forest type, with trees assigned visibility characteristics based on remote sensing parameters.

The function `simulate_and_save_forest` begins by checking if the file for each forest iteration already exists in the output directory. If a file is detected for a given iteration, that iteration is skipped to avoid redundant processing. For any new files, the function generates a random alpha value within the specified range, simulates a forest with DBH values following this distribution, calculates tree visibility, and saves the resulting dataset as a CSV file in the output directory. This allows for efficient reuse of existing files while producing a variety of forest datasets.

```{r}
# Set parameters
n_forests <- 500
alpha_range <- c(0, 5)  # Range for the alpha (shape) parameter
output_dir <- "simulatedforests/"  # Set the path for saving CSV files

# Create a helper function to generate and save forest data
simulate_and_save_forest <- function(forest_type, p_gymnosperm, location, output_dir, n_forests = 500) {
  # Ensure the output directory exists
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Loop over the number of forests to simulate
for (i in 1:n_forests) {
    # Define a generic pattern for checking existing files
  file_pattern <- paste0("forest_", gsub(" ", " ", forest_type),"_", i, ".csv")
  existing_files <- list.files(output_dir, pattern = file_pattern, full.names = TRUE)

  # Check if any files match the pattern
  if (length(existing_files) > 0) {
    cat("File already exists for iteration", i, "and forest type:", forest_type, "- Skipping\n")
    next  # Skip to the next iteration if the file exists
  }

# Define file name and path with the specific alpha value
file_name <- paste0("forest_", gsub(" ", "_", forest_type), "_alpha_", round(alpha_value, 2), "_", i, ".csv")
file_path <- file.path(output_dir, file_name)
  # Generate random alpha (shape) value
  alpha_value <- runif(1, min = alpha_range[1], max = alpha_range[2])



    
    # Simulate DBH values from the truncated Pareto distribution
    dbh <- rtruncpareto(n = 2000, lower = 3, upper = 50, shape = alpha_value)
    
    # Simulate forest with the specified parameters
    forest_data <- simulate_forest(dbh, p_gymnosperm = p_gymnosperm, location = location, forest_type = forest_type)
    
    # Assign tree visibility
    forest_data <- assign_tree_visibility(forest_data, plot_width = 50, plot_height = 50, overlap_threshold = 0.7)
    
    # Add the alpha value to the data frame
    forest_data$alpha <- alpha_value
    
    # Save to CSV
    write.csv(forest_data %>%
                data.frame() %>%
                select(-geometry), file_path, row.names = FALSE)
    
    cat("Saved file:", file_name, "\n")
  }
}
```

Two types of forests are generated and saved using the `simulate_and_save_forest` function. Each forest type represents a unique species composition and ecological setting, and these distinctions are reflected in the parameters used for tree simulation:

1. **Temperate Coniferous Forests** – This dataset simulates a forest composed entirely of gymnosperms, located in the Nearctic region. 
2. **Temperate Mixed Forests** – This dataset simulates a forest with an equal mix of gymnosperms and angiosperms (50/50), also located in the Nearctic region.

These simulations help establish data that varies not only by species composition but also by forest structure, allowing for a broad analysis across forest types under differing alpha values. Each dataset is saved to the output directory for later use.



```{r}
# Generate and save forests for temperate coniferous forests (all gymnosperms)
simulate_and_save_forest(
  forest_type = "Temperate coniferous forests",
  p_gymnosperm = 1,  # All gymnosperms
  location = "Nearctic",
  output_dir = output_dir
)

# Generate and save forests for temperate mixed forests (50/50 gymnosperms and angiosperms)
simulate_and_save_forest(
  forest_type = "Temperate mixed forests",
  p_gymnosperm = 0.5,  # 50/50 gymnosperms and angiosperms
  location = "Nearctic",
  output_dir = output_dir
)

```
### Setting up the Stan Model

In this section, the Stan code is defined to model the truncated Pareto distribution. The goal of this model is to estimate the shape parameter **alpha** for a given dataset of observed tree diameters that are subject to both a lower and upper truncation. The code is structured as follows:

- **Data Block**: Specifies the inputs to the model, including:
  - `N`: Number of observations.
  - `x_min`: The minimum threshold of the distribution.
  - `trunc_point`: The truncation threshold below which data is not observed.
  - `trunc_upper`: The maximum threshold, above which data is capped.
  - `x`: The observed data within the truncation limits.
  
- **Parameters Block**: Defines the parameter `alpha`, which is the shape parameter for the Pareto distribution. This parameter is constrained to be between 0 and 5.

- **Model Block**: 
  - A **lognormal prior** is set for `alpha`, reflecting a prior belief that `alpha` is likely to be centered around 1, with some flexibility.
  - The **likelihood function** is adjusted to account for the truncation of the data. The likelihood is computed using the cumulative distribution function (CDF) of the truncated Pareto distribution, ensuring that the observations are appropriately normalized to the observed range.

This Stan model will be used later in the pipeline to estimate the value of **alpha** from the simulated tree data.


```{r}

stan_predict_alpha <-"data {
	int<lower=0> N;                  // Number of observations
	real<lower=0> x_min;             // Minimum threshold for entire distribution (e.g., 3)
	real<lower=0> trunc_point;       // Observed data starts at this truncation threshold (e.g., 20)
	real<lower=trunc_point> trunc_upper;  // Observed data is capped at this upper threshold (e.g., 50)
	vector<lower=0>[N] x;            // Observed data, limited to range [trunc_point, trunc_upper]
}

parameters {
	real<lower=0, upper=5> alpha;    // Shape parameter for Pareto distribution
}

model {
	// Prior for alpha
	alpha ~ lognormal(1, 1);

	// Calculate the truncated cumulative probability in the observed range
	real p_trunc = pareto_cdf(trunc_upper | x_min, alpha) - pareto_cdf(trunc_point | x_min, alpha);

	// Adjusted likelihood for the double-truncated Pareto distribution
	for (n in 1:N) {
		target += pareto_lpdf(x[n] | x_min, alpha) - log(p_trunc);
	}
}
"

```
### Step 2: Fitting the Stan Model with Dynamic Truncation

In this section, the pipeline fits the **Stan model** to the observed tree data, with dynamic truncation applied to ensure a sufficient number of data points for robust estimation. Here's an overview of the steps involved:

1. **Minimum Tree Count Threshold**:
   - The minimum number of trees required (`min_tree_count`) is set to ensure stable estimates. If fewer trees are available after truncation, the model will adjust the truncation point.
   
2. **File Handling**:
   - The code loads the forest data files for a specified **forest type** (e.g., "Temperate coniferous forests") from the output directory.
   - For each forest file, the following steps are executed.

3. **Initial Truncation and Adjustment**:
   - The initial truncation threshold (`trunc_point`) is set at 25, and the upper truncation (`trunc_upper`) is set at 50. These values can be adjusted depending on the specific dataset.
   - The code checks for **visible trees** (based on the visibility attribute) and applies the truncation. If the number of visible trees within the truncation range is below the required threshold, the truncation point is lowered step by step to include more data.

4. **Fitting the Model**:
   - Once a sufficient number of trees are available, the Stan model is fitted to the truncated data using the `sampling()` function. This model estimates the **alpha** parameter of the truncated Pareto distribution.

5. **Storing and Summarizing Results**:
   - For each successful fit, the true (`alpha_true`) and estimated (`alpha_est`) alpha values are stored.
   - A **summary** of the results is generated, including calculating the **mean absolute error** and **root mean squared error (RMSE)** between the true and estimated alpha values.

6. **Visualization**:
   - A scatter plot is generated to compare the true and estimated alpha values, with a reference line showing perfect estimation. This helps assess the model's performance visually.  The **true alpha** values are placed on the **x-axis**, and the **estimated alpha** values are placed on the **y-axis**, following the recommendations of Gervasio Piñeiro, Susana Perelman, Juan P. Guerschman, and José M. Paruelo in their 2008 paper, *How to evaluate models: Observed vs. predicted or predicted vs. observed?* (Ecological Modelling, Volume 216, Issues 3–4). This approach facilitates an accurate visual assessment of model performance, highlighting deviations between predicted and true values.

This section is critical for evaluating the ability of the Stan model to recover the **alpha** parameter, considering dynamic truncation to handle varying numbers of visible trees across different simulations.


```{r, echo = FALSE}
stan_model <- stan_model(model_code = stan_predict_alpha)
process_forest_simulations <- function(
  forest_type, 
  output_dir, 
  stan_model, 
  x_min = 3, 
  trunc_upper = 50, 
  min_tree_count = 10, 
  warmup = 1000, 
  iter = 5000, 
  chains = 2, 
  cores = 1, 
  refresh = 0
) {
  # List files matching the forest type
  simulatedforestlist <- list.files(output_dir, pattern = forest_type, full.names = TRUE)
  
  # Initialize data storage
  alphadata <- list()
  
  # Loop through each forest simulation file
  for (i in seq_along(simulatedforestlist)) {
    forest_data_frame <- fread(simulatedforestlist[i])
    
    # Extract relevant data
    trunc_point <- 20
    visible_data <- (forest_data_frame %>%
                       filter(Visibility == "Visible"))$DBH
    alpha_true <- forest_data_frame$alpha %>% unique()
    
    # Apply initial left truncation
    x_truncated <- visible_data[visible_data >= trunc_point & visible_data <= trunc_upper]
    
    # Step 2: Adjust trunc_point if necessary
    while (length(x_truncated) < min_tree_count && trunc_point > x_min) {
      trunc_point <- trunc_point - 1  # Decrease by 1
      x_truncated <- visible_data[visible_data >= trunc_point & visible_data <= trunc_upper]
    }
    
    # Proceed if final truncated data meets threshold
    if (length(x_truncated) >= min_tree_count) {
      # Step 3: Fit the Stan model to the truncated data
      stan_data <- list(
        N = length(x_truncated),
        trunc_point = trunc_point,
        trunc_upper = trunc_upper,
        x_min = x_min,
        x = x_truncated
      )
      
      fit <- tryCatch({
        sampling(
          stan_model, 
          data = stan_data, 
          iter = iter, 
          warmup = warmup, 
          chains = chains, 
          cores = cores, 
          refresh = refresh
        )
      }, error = function(e) {
        message(paste("Error fitting model at iteration", i, ": ", e$message))
        return(NULL)
      })
      
      # If successful, store the results
      if (!is.null(fit)) {
        alpha_est <- summary(fit, pars = "alpha")$summary[,"mean"]
        alphadata[[i]] <- data.frame(
          alpha_true = alpha_true,
          alpha_est = alpha_est,
          trunc_point = trunc_point
        )
      }
    }
  }
  
  # Summarize results
  results_df <- do.call(rbind, alphadata) %>%
    filter(alpha_true >= 0.5)
  
  return(results_df)
}

```

```{r}
forest_type = "Temperate mixed forests"
simulatedforestlist<-list.files(output_dir, pattern=forest_type, full.names = TRUE)
results_df<-process_forest_simulations(forest_type, output_dir, stan_model, x_min = 3, trunc_upper = 50, min_tree_count = 50)
# Calculate metrics and plot
mean_abs_error <- mean(abs(results_df$alpha_true - results_df$alpha_est))
rmse <- sqrt(mean((results_df$alpha_true - results_df$alpha_est)^2))
cat("Mean Absolute Error:", mean_abs_error, "\n")
cat("Root Mean Squared Error:", rmse, "\n")

# Fit linear model and summarize results
lm_model <- lm(alpha_true ~ alpha_est, data = results_df)
lm_summary <- summary(lm_model)


# Print the linear model summary
cat("Linear Model Summary:\n")
print(lm_summary)



ggplot(results_df, aes(x = alpha_est, y = alpha_true)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "True vs. Estimated Alpha Values\nwith Dynamic Truncation, Coniferous Forest",
       x ="Estimated Alpha",
       y =  "True Alpha") +
  theme_minimal()

```
```{r}

forest_type = "Temperate coniferous forests"
simulatedforestlist<-list.files(output_dir, pattern=forest_type, full.names = TRUE)
results_df_conifer<-process_forest_simulations(forest_type, output_dir, stan_model, x_min = 3, trunc_upper = 50, min_tree_count = 50)
# Calculate metrics and plot
mean_abs_error <- mean(abs(results_df_conifer$alpha_true - results_df_conifer$alpha_est))
rmse <- sqrt(mean((results_df_conifer$alpha_true - results_df_conifer$alpha_est)^2))
cat("Mean Absolute Error:", mean_abs_error, "\n")
cat("Root Mean Squared Error:", rmse, "\n")

# Fit linear model and summarize results
lm_model_conifer <- lm(alpha_true ~ alpha_est, data = results_df_conifer)
lm_summary_conifer <- summary(lm_model_conifer)


# Print the linear model summary
cat("Linear Model Summary:\n")
print(lm_summary_conifer)



ggplot(results_df_conifer, aes(x = alpha_est, y = alpha_true)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "True vs. Estimated Alpha Values\nwith Dynamic Truncation, Coniferous Forest",
       x ="Estimated Alpha",
       y =  "True Alpha") +
  theme_minimal()
```
## Estimating Alpha with Real-World Data

In this section, we implement a Bayesian model to estimate the shape parameter \( \alpha \) of a truncated Pareto distribution using real-world forest data. This approach introduces an informative prior that adapts dynamically to crown condition scores and tree height characteristics to address uncertainties in data collection and measurement.

### Background

Field surveys often provide data on tree diameters, which can be used to infer \( \alpha \), a key parameter describing the size-abundance relationship. However, observational biases, such as smaller trees being obscured by canopy cover or variability in sampling effort, can introduce noise and uncertainty into the estimation process. Additionally, the quality of the data can vary across plots, necessitating a flexible modeling approach.

### Model Features

1. **Truncated Likelihood**: The model accounts for the fact that observed tree diameters are limited to a specific range (e.g., 20–50 cm DBH). The likelihood adjusts for this truncation, ensuring accurate inference within the specified range.
2. **Informative Prior**: A prior on \( \alpha \) incorporates additional knowledge about the site, such as average crown score and maximum tree height:
   - **Crown Score Adjustment**: Crown scores (ranging between 0 and 1) serve as a proxy for data reliability. The prior is weighted dynamically using a logistic sigmoid function:
     - **Low Crown Scores**: Indicates potential observational uncertainty, leading to stronger reliance on the prior.
     - **High Crown Scores**: Suggests reliable data, resulting in less influence from the prior.
   - **Tree Height Dependency**: Maximum tree height influences the prior mean for \( \alpha \), reflecting known ecological relationships between forest structure and size-abundance patterns.
3. **Dynamic Prior Weighting**: By modifying the prior’s weight based on observed data characteristics, the model flexibly adapts to variations in data quality and site-specific conditions.

### Objectives

1. To estimate \( \alpha \) for each plot using observed tree diameter data and ecological covariates (crown scores and maximum tree height).
2. To evaluate the influence of crown score and tree height on the estimated \( \alpha \) values.
3. To assess how the use of an informative, dynamic prior impacts the estimation process.

The next code chunk implements this model in Stan for the real-world dataset.

```{r, echo = FALSE}
process_forest_simulations <- function(
  forest_type, 
  output_dir, 
  stan_model, 
  x_min = 3, 
  trunc_upper = 50, 
  min_tree_count = 10, 
  warmup = 1000, 
  iter = 2000, 
  chains = 2, 
  cores = 1, 
  refresh = 0
) {
  # List files matching the forest type
  simulatedforestlist <- list.files(output_dir, pattern = forest_type, full.names = TRUE)
  
  # Initialize data storage
  alphadata <- list()
  
  # Loop through each forest simulation file
  for (i in seq_along(simulatedforestlist)) {
    forest_data_frame <- fread(simulatedforestlist[i])
    
    # Add crown_scor column with all values set to 1 (perfect crown score for simulations)
    forest_data_frame$crown_scor <- 1
    
    # Extract relevant data
    trunc_point <- 20
    visible_data <- (forest_data_frame %>%
                       filter(Visibility == "Visible"))$DBH
    height_data <- (forest_data_frame %>%
                      filter(Visibility == "Visible"))$Height
    alpha_true <- forest_data_frame$alpha %>% unique()
    
    # Compute the maximum height for the visible trees
    max_height <- max(height_data, na.rm = TRUE)
    
    # Apply initial left truncation
    x_truncated <- visible_data[visible_data >= trunc_point & visible_data <= trunc_upper]
    
    # Step 2: Adjust trunc_point if necessary
    while (length(x_truncated) < min_tree_count && trunc_point > x_min) {
      trunc_point <- trunc_point - 1  # Decrease by 1
      x_truncated <- visible_data[visible_data >= trunc_point & visible_data <= trunc_upper]
    }
    
    # Proceed if final truncated data meets threshold
    if (length(x_truncated) >= min_tree_count) {
      # Prepare Stan data with added crown_scor and max_height
      stan_data <- list(
        N = length(x_truncated),
        trunc_point = trunc_point,
        trunc_upper = trunc_upper,
        x_min = x_min,
        x = x_truncated,
        crown_scor = rep(1, length(x_truncated)),  # Perfect crown scores for simulations
        max_height = max_height
      )
      
      # Fit the model
      fit <- tryCatch({
        sampling(
          stan_model, 
          data = stan_data, 
          iter = iter, 
          warmup = warmup, 
          chains = chains, 
          cores = cores, 
          refresh = refresh
        )
      }, error = function(e) {
        message(paste("Error fitting model at iteration", i, ": ", e$message))
        return(NULL)
      })
      
      # If successful, store the results
      if (!is.null(fit)) {
        alpha_est <- summary(fit, pars = "alpha")$summary[,"mean"]
        alphadata[[i]] <- data.frame(
          alpha_true = alpha_true,
          alpha_est = alpha_est,
          trunc_point = trunc_point
        )
      }
    }
  }
  
  # Summarize results
  results_df <- do.call(rbind, alphadata) %>%
    filter(alpha_true >= 0.5)
  
  return(results_df)
}
```


```{r}
### THIS NEEDS FIXING. IT ISN'T WORKING WELL. SO FAR THE REAL_WORLD_ADJUSTMENTS ONE WORKS THE BEST
stan_prior<-"
data {
    int<lower=0> N;                  // Number of observations
    real<lower=0> x_min;             // Minimum threshold for the distribution (e.g., 3)
    real<lower=0> trunc_point;       // Observed data starts at this truncation threshold (e.g., 20)
    real<lower=trunc_point> trunc_upper;  // Observed data is capped at this upper threshold (e.g., 50)
    vector<lower=0, upper=1>[N] crown_scor; // Average crown score for each plot (between 0 and 1)
    vector<lower=0>[N] x;            // Observed data, limited to range [trunc_point, trunc_upper]
    real max_height;                 // Maximum height of trees in the plot
}

parameters {
    real<lower=0, upper=5> alpha;    // Shape parameter for Pareto distribution
}

transformed parameters {
    real sigmoid_prior_weight;       // Weight for prior based on crown score
    real prior_mean;                 // Mean of the prior
    real prior_variance;             // Variance of the prior

    // Adjust prior mean based on max height
    prior_mean = 3.92 - 1.88 * log10(max_height + 1e-6); // Log10 relationship with max_height
    
    // Apply the sigmoid function to determine prior weight based on crown scores
    // Higher crown scores lead to less reliance on the prior
    sigmoid_prior_weight = 1 / (1 + exp(25 * (mean(crown_scor) - 0.5)));

    // Dynamic prior variance: Tighter at low alpha, broader at high alpha
    prior_variance = 0.05 / sigmoid_prior_weight + (0.2 * prior_mean); // Added dependence on prior_mean
}

model {
    // Apply the adjusted prior by modifying its log-likelihood with the prior weight
    target += sigmoid_prior_weight * lognormal_lpdf(alpha | prior_mean, sqrt(prior_variance));
    
    // Calculate the truncated cumulative probability in the observed range
    real p_trunc = pareto_cdf(trunc_upper | x_min, alpha) - pareto_cdf(trunc_point | x_min, alpha);
    
    // Likelihood: Adjusted for the double-truncated Pareto distribution
    for (n in 1:N) {
        target += pareto_lpdf(x[n] | x_min, alpha) - log(p_trunc);
    }
}
"
```

```{r}
stan_prior_model<-stan_model(model_code=stan_prior)

# Use the process_forest_simulations function to get results
results_df <- process_forest_simulations(
  forest_type = "Temperate coniferous forests", 
  output_dir = output_dir, 
  stan_model = stan_prior_model, 
  warmup = 50, 
  iter = 2000, 
  chains = 2, 
  cores = 1, 
  refresh = 0
)

# Fit linear model and summarize results
lm_model_conifer <- lm(alpha_true ~ alpha_est, data = results_df)
lm_summary_conifer <- summary(lm_model_conifer)

# Print the linear model summary
cat("Linear Model Summary:\n")
print(lm_summary_conifer)

# Create the plot
ggplot(results_df, aes(x = alpha_est, y = alpha_true)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "True vs. Estimated Alpha Values\nwith Informative Prior, Coniferous Forest",
    x = "Estimated Alpha",
    y = "True Alpha"
  ) +
  theme_minimal()

```



## Recovering Real-World Alpha Values Using NEON Data

In this section, we will attempt to recover the true alpha values for real-world forests using our previously developed method. Specifically, we will apply our model to actual forest data from the **National Ecological Observatory Network (NEON)** to estimate the alpha (shape) parameter of the truncated Pareto distribution for tree diameters. 

### What is NEON?

The **National Ecological Observatory Network (NEON)** is a large-scale, long-term ecological monitoring program that collects data from various ecosystems across the United States. The goal of NEON is to provide high-quality, open-access data to researchers, policymakers, and the public to understand ecological processes and environmental changes. NEON collects data on various environmental variables, including vegetation characteristics, soil conditions, climate, and biodiversity. This data is gathered from over 80 sites that represent different ecological zones, such as forests, grasslands, and wetlands. The NEON dataset includes detailed information on tree measurements, such as tree diameter at breast height (DBH), which we will use in our analysis.

For this analysis, we will focus on using the tree DBH data, particularly tree visibility data, to attempt to recover the alpha value for forests from NEON. We will simulate forest structures using different alpha values (as outlined in previous sections), compare those simulated values to the observed data, and evaluate how well our method can predict the true alpha for the real-world forests.

The goal of this section is to demonstrate the applicability of our model for real-world data and to evaluate its performance against actual ecological data collected through remote sensing and on-the-ground measurements. 

In the following code chunk, we will start by loading the NEON data and preparing it for analysis.

```{r}
data<-fread("R:\\Adam Eichenwald\\NEON_treesall_filtered_tosubplot.csv")%>%
  filter(stemDiameter >= 3 & stemDiameter <=50)%>%
  group_by(individualID)%>%
  filter(year == max(year))%>%
  ungroup()

model <- stan_model(file = "density1_simplified.stan")
for(i in unique(data$siteID)){
  uniqueplace<-i
  test <- data %>%
    mutate(year=year(date))%>%
    filter(siteID == uniqueplace)%>%
    tidyr::drop_na(stemDiameter)

    N <- length(test$stemDiameter)
    x <- test$stemDiameter
    x_min <- 3
    x_max <- 50
    if (N > 1){
    stan_dat <- list(N = N, x = x, x_min = x_min, x_max = x_max)
    fit <- sampling(model, data = stan_dat, iter = 9000, warmup = 6000, chains = 4, refresh= 0)
    
    data_out <- summary(fit)$summary %>%
      data.frame() %>%
      mutate(N_Trees = nrow(test), 
             siteID = uniqueplace, 
            corrected_slope = -(mean + 1), variables = rownames(.)) %>%
      filter(variables == "alpha")
    fwrite(data_out, paste0("NEON_fullsites_recenttrees\\",uniqueplace,".csv"))
    }else{
      next
    }
}


slopes<-list.files("NEON_fullsites_recenttrees\\", full.names=TRUE)%>%
  lapply(fread)%>%
  rbindlist()%>%
  select(mean, se_mean, sd, N_Trees, siteID)%>%
  filter(N_Trees >= 100)
```

This code section processes NEON tree data to estimate the Pareto distribution parameter alpha, which characterizes the size distribution of visible trees at each site. 

After loading the NEON dataset, it filters for trees with diameters between 3 and 50 cm to focus on a specific size range, retaining only the latest measurement for each tree. For each site in the dataset, it then uses the `density1_simplified.stan` model in Stan to fit a truncated Pareto distribution, estimating alpha based on the observed stem diameters at that site. If a site has an insufficient number of observations, it is skipped to ensure reliable parameter estimation. 

The results, including each site’s estimated alpha, total tree count, and corrected slope, are saved as individual CSV files, which are then combined for further analysis. This setup allows us to compare alpha values across sites and understand forest structure patterns represented in the NEON data.

### Processing NEON Shapefiles to Derive DBH

In this section, we iterate over a series of NEON shapefiles to calculate the diameter at breast height (DBH) for each tree. The shapefiles, stored in the `NEON_Weinstein_crownscropped_corrected` directory, contain individual tree information, including crown height and area, from which we can estimate DBH. The code follows several steps to ensure accurate data processing.

1. **Shapefile Reading and Geometry Validation**:
   Each shapefile is read using the `st_read()` function. Since shapefiles sometimes contain invalid geometries that can interrupt calculations, we check each file for validity using `st_is_valid()`. For any invalid geometries, `st_make_valid()` is applied to repair them, ensuring compatibility with subsequent calculations.

2. **Calculating Perimeter, Diameter, and DBH**:
   - **Perimeter Calculation**: We compute the crown perimeter for each tree using `st_perimeter()` and convert it to numeric format to facilitate further calculations.
   - **Diameter Calculation**: We estimate the canopy diameter from the perimeter and area using the equation `Diameter = 0.5 * (sqrt(perimeter^2 - (8 * area)))`. This formula is based on the mathematical relationship between area and perimeter.
   - **DBH Calculation**: To derive DBH, we use the `dbh()` function from the `itcSegment` package, which implements an allometric equation from Jucker et al. (2017). This equation relates canopy area (`CA`) and height (`H`) to DBH, making it suitable for estimating DBH from remotely sensed crown data.

3. **Data Cleaning and Selection**:
   After calculating DBH, we filter out records where DBH equals zero to avoid inaccuracies. Then, we select only essential columns (`height`, `area`, `Year`, `Site`, `dbh`) for further analysis.

4. **Combining Data**:
   Each shapefile is converted to a data frame, excluding the geometry column, and stored in a list. Finally, all data frames are combined into one using `rbindlist()`, creating a comprehensive dataset with DBH, height, area, and site-specific metadata for all trees across the processed shapefiles.

This resulting dataset, `final_data`, provides a standardized summary of tree attributes across the NEON sites, enabling further analysis and validation of tree dimensions and spatial distribution across different forest plots.

```{r}

# Directory containing the shapefiles
shapefile_directory <- "NEON_Weinstein_crownscropped_corrected"
shapefiles <- list.files(shapefile_directory, pattern = "\\.shp$", full.names = TRUE)
subplots<-read_sf("R://Adam Eichenwald//smallest_subplots.shp")
st_join(shapefile_data, smallestsubplots)%>%
  group_by(plotID)%>%summarize(n())
# Initialize an empty list to store the processed data frames
processed_data <- list()

# Loop over each shapefile
for (shp_file in shapefiles) {
  
  # Read the shapefile
  shapefile_data <- st_read(shp_file, quiet = TRUE)
   # Validate and correct geometries if needed
  if (any(!st_is_valid(shapefile_data))) {
    shapefile_data <- st_make_valid(shapefile_data)
  }
  # Ensure the area and perimeter are in numeric format
  shapefile_data <- shapefile_data %>%
    mutate(
      perimeter = as.numeric(st_perimeter(.)),
      area = as.numeric(st_area(.))
    ) %>%
    # Calculate Diameter and DBH based on your provided formulas
    mutate(
      Diameter = 0.5 * (sqrt(perimeter^2 - (8 * area))),
      dbh = dbh(H = height, CA = Diameter)
    ) %>%
    # Select only the required columns
    select(height, area, Year, Site, dbh)%>%
    filter(dbh != 0)
  
  # Convert to a data frame and store in the list
  processed_data[[shp_file]] <- as.data.frame(shapefile_data)%>%
    select(-geometry)
}

# Combine all processed data frames into one using rbindlist from data.table
final_data <- rbindlist(processed_data, fill = TRUE)
head(final_data)
```

## Alpha Estimation for NEON Sites

This section estimates the alpha parameter for each unique NEON site using the observed DBH (diameter at breast height) values. The workflow adapts the alpha estimation process used in the simulated forest dataset to analyze NEON data. Here’s a summary of the key steps involved:

1. **Setting up Data and Truncation**:
   - First, we extract unique site names from the NEON data and initialize parameters to control the left (`trunc_point`) and right (`trunc_upper`) truncation limits, which define the DBH range used to estimate alpha. These are set based on tree DBH range, ensuring we focus on a meaningful subset of the data for analysis.

2. **Iterating Through Each Site**:
   - The code loops over each unique `Site` in the NEON dataset. For each site, it filters the data to extract only the DBH values for trees measured within that site.

3. **Applying Dynamic Truncation**:
   - Using a starting truncation point (`trunc_point`), we select trees with DBH values within this range. If the resulting dataset contains fewer than a minimum number of trees (`min_tree_count`), `trunc_point` is lowered incrementally to include more trees until this threshold is met.

4. **Fitting the Stan Model**:
   - For each site with sufficient tree data, the Stan model is used to estimate alpha for the DBH distribution within the truncated range. The model input data (`stan_data`) includes the DBH values for trees in the site as well as the truncation points.
   - If the model fails to fit due to data issues or convergence problems, the code moves to the next site.

5. **Collecting and Summarizing Results**:
   - Alpha estimates for each site are stored in a list. These results are combined into a single data frame (`neon_results_df`), where each row corresponds to a site’s estimated alpha value.
   - If available, true alpha values are compared to the estimates, calculating mean absolute error and root mean squared error (RMSE) to evaluate accuracy. 

6. **Plotting Estimated Alpha Values**:
   - A scatter plot of estimated versus true alpha values is generated if true values are known. If not, a plot of estimated alpha values across sites is created, visualizing how alpha varies among NEON sites.
   
This approach provides an efficient method to analyze the DBH distributions for NEON sites, allowing us to examine forest structure across multiple locations.

```{r}
# Initialize an empty list to store alpha estimation results for each site
neon_alphadata <- list()
# final_data <- list.files("NEON_Weinstein_trees", full.names = TRUE) %>%
#   lapply(fread) %>%
#   rbindlist() %>%
#   mutate(
#     # Calculate the width and height from the bounding box coordinates
#     width = right - left,
#     height = top - bottom,
#     # Calculate the perimeter using the formula: Perimeter = 2 * (width + height)
#     perimeter = 2 * (width + height)
#   ) %>%
#   # Calculate Diameter and DBH based on your provided formulas
#   mutate(
#     Diameter = 0.5 * (sqrt(perimeter^2 - (8 * area))),
#     dbh = dbh(H = height, CA = Diameter)
#   ) %>%
#   # Select only the required columns
#   select(height, area, Year, Site, dbh) %>%
#   filter(dbh != 0)

# Define truncation and model parameters
trunc_upper <- 50
xmin <- 3
min_tree_count <- 50  # Adjust this if needed

# Loop over each unique Site in the NEON data
for (unique_site in unique(final_data$Site)) {
  
  # Filter the data for the current site
  site_data <- final_data %>% 
    filter(Site == unique_site)
  alpha_true<-(slopes%>%
    filter(siteID == unique_site))$mean
  
  # If alpha_true doesn't exist (empty result), skip this iteration
  if (length(alpha_true) == 0) {
    next
  }
  
  # Extract the DBH column and apply initial truncation points
  dbh_data <- site_data$dbh
  trunc_point <- 20  # Initial truncation point
  
  # Apply left and right truncation
  x_truncated <- dbh_data[dbh_data >= trunc_point & dbh_data <= trunc_upper]
  
  # Adjust truncation if necessary based on the minimum tree count
  while (length(x_truncated) < min_tree_count && trunc_point > xmin) {
    trunc_point <- trunc_point - 1
    x_truncated <- dbh_data[dbh_data >= trunc_point & dbh_data <= trunc_upper]
  }
  
  # If truncated data meets the tree count threshold, fit the Stan model
  if (length(x_truncated) >= min_tree_count) {
    stan_data <- list(N = length(x_truncated), 
                      trunc_point = trunc_point, 
                      trunc_upper = trunc_upper, 
                      x_min = xmin, 
                      x = x_truncated)
    
    # Try fitting the model; catch any errors that arise
    fit <- tryCatch({
      sampling(stan_model, data = stan_data, iter=2000, chains = 2, refresh = 0)
      }, error = function(e) {
      message(paste("Error fitting model for Site", unique_site, ": ", e$message))
      return(NULL)
    })
    
    # If fit was successful, extract alpha and store results
    if (!is.null(fit)) {
      alpha_est <- summary(fit, pars = "alpha")$summary[,"mean"]
      neon_alphadata[[unique_site]] <- data.frame(Site = unique_site, alpha_true = alpha_true, alpha_est = alpha_est, trunc_point = trunc_point)
    }
  }
}

# Combine all alpha estimation results into a single data frame
neon_results_df <- do.call(rbind, neon_alphadata)

# Assuming the results from the Stan model are stored in a data frame called `neon_results_df`
ggplot(neon_results_df, aes(x = alpha_est, y = alpha_true)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "True vs. Estimated Alpha Values\nfor NEON Sites",
       x = "Estimated Alpha",
       y = "True Alpha") +
  theme_minimal()+xlim(0,5)+ylim(0,5)+geom_label(aes(label = Site))


```
